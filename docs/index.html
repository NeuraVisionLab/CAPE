<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CAPE: Connectivity-Aware Path Enforcement Loss for Curvilinear Structure Delineation">
  <meta name="keywords" content="CAPEF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CAPE: Connectivity-Aware Path Enforcement Loss for Curvilinear Structure Delineation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- 1. In your <head>, add Prism -->
  <link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css"
  />
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"
  defer
  ></script>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"
  defer
  ></script>

  
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/normalize-whitespace/prism-normalize-whitespace.min.js"
  defer
  ></script>

</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>
  </div>
</nav> -->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1
          class="publication-title title
                 is-size-4-mobile   
                 is-size-3-tablet    
                 is-size-2-desktop"  
          style="color: #44708d;"
        >
          CAPE: Connectivity-Aware Path Enforcement Loss for Curvilinear Structure Delineation
        </h1>          
        <div
          class="publication-authors
                 is-size-6-mobile    
                 is-size-5-desktop"  
          style="display: flex; justify-content: center; flex-wrap: wrap; gap: 0.5rem;"
        >
            <span class="author-block" style="position: relative; padding-right: 1.5rem; display: inline-block; line-height: 1.2;">
              Elyar Esmaeilzadeh
              <a href="https://orcid.org/0009-0003-5610-2604" target="_blank" rel="noopener" aria-label="ORCID Elyar Esmaeilzadeh"
                style="position: absolute; top: 0rem; right: 0; display: inline-block; width: 1.2rem; height: 1.2rem;">
                <img src="https://orcid.org/sites/default/files/images/orcid_24x24.png" alt="ORCID" style="width: 100%; height: 100%;">
              </a>
              
            </span>

            <span class="author-block" style="position: relative; padding-right: 1.5rem; display: inline-block; line-height: 1.2;">
              , Ehsan Garaaghaji
              <a href="https://orcid.org/0009-0003-2720-7415" target="_blank" rel="noopener" aria-label="ORCID Ehsan Garaaghaji"
                style="position: absolute; top: 0rem; right: 0; display: inline-block; width: 1.2rem; height: 1.2rem;">
                <img src="https://orcid.org/sites/default/files/images/orcid_24x24.png" alt="ORCID" style="width: 100%; height: 100%;">
              </a>
            </span>,&nbsp;

            <span class="author-block" style="position: relative; padding-right: 1.5rem; display: inline-block; line-height: 1.2;">
              , Farzad Hallaji Azad
              <a href="https://orcid.org/0009-0003-3882-4275" target="_blank" rel="noopener" aria-label="ORCID Farzad Hallaji Azad"
                style="position: absolute; top: 0rem; right: 0; display: inline-block; width: 1.2rem; height: 1.2rem;">
                <img src="https://orcid.org/sites/default/files/images/orcid_24x24.png" alt="ORCID" style="width: 100%; height: 100%;">
              </a>
            </span>

            <span class="author-block" style="position: relative; padding-right: 1.5rem; display: inline-block; line-height: 1.2;">
              , Doruk Oner
              <a href="https://orcid.org/0000-0002-9403-4628" target="_blank" rel="noopener" aria-label="ORCID Doruk Oner"
                style="position: absolute; top: 0rem; right: 0; display: inline-block; width: 1.2rem; height: 1.2rem;">
                <img src="https://orcid.org/sites/default/files/images/orcid_24x24.png" alt="ORCID" style="width: 100%; height: 100%;">
              </a>
            </span>
          </div>
          <div class="is-size-6-mobile    
                  is-size-5-desktop
                  publication-authors" style="margin-top: 0.5rem;">
            NeuraVision Lab, Bilkent University, Ankara, Turkey
          </div>
          <div class="is-size-6-mobile    
                  is-size-5-desktop
                  publication-authors">
            <span class="author-block">NeuraVision Lab, Bilkent University</span>
          </div>

<!--           <div class="columns is-centered">
            <div class="column has-text-centered">
              <img src="./static/images/bilkent_logo.png" alt="Bilkent University Logo" style="max-width: 200px; margin-top: 20px;">
            </div>
          </div> -->

          <div class="columns is-centered" style="margin-top: 20px; gap: 0;">
            <div class="column is-narrow has-text-centered" style="padding: 0;">
              <img src="./static/images/bilkent_logo.png" alt="Bilkent University Logo" style="width: 90%; height: auto; max-width: 300px;">
            </div>
            <div class="column is-narrow has-text-centered" style="padding: 0;">
              <img src="./static/images/miccai2025_logo.png" alt="MICCAI2025" style="width: 60%; height: auto; max-width: 200px;">
            </div>
          </div>
          
          <div class="column has-text-centered" style="margin-top: 1rem;">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2504.00753"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2504.00753"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/NeuraVisionLab/CAPE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
      
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="has-text-centered">
        <video id="teaser"
               autoplay
               muted
               loop
               playsinline
               style="width: 35%; height: auto; ">   <!--border: 2px solid #ccc; border-radius: 8px; -->
          <source src="./static/videos/output_video.mp4" type="video/mp4">
        </video>
      </figure>
      <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
        <strong>CAPE</strong> increases the connectivity of curvilinear structures in segmentation tasks. The video above illustrates the effectiveness of our approach in enhancing the connectivity.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Promoting the connectivity of curvilinear structures, such as neuronal processes in biomedical scans and blood vessels in CT images, remains a key challenge in semantic segmentation. Traditional pixel-wise loss functions, including cross-entropy and Dice losses, often fail to capture high-level topological connectivity, resulting in topological mistakes in graphs obtained from prediction maps. In this paper, we propose <strong>CAPE (Connectivity-Aware Path Enforcement)</strong>, a novel loss function designed to enforce connectivity in graphs obtained from segmentation maps by optimizing a graph connectivity metric. <strong>CAPE</strong> uses the graph representation of the ground truth to select node pairs and determine their corresponding paths within the predicted segmentation through a shortest-path algorithm. Using this, we penalize both disconnections and false positive connections, effectively promoting the model to preserve topological correctness. Experiments on 2D and 3D datasets, including neuron and blood vessel tracing demonstrate that <strong>CAPE</strong> significantly improves topology-aware metrics and outperforms state-of-the-art methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: justify;">
          <h2 class="title is-3 has-text-centered">Computation of L<sub>CAPE</sub></h2>
          
          <figure class="has-text-centered">
            <img src="./static/images/FIG_NEW.png" alt="CAPE visual effect example" style="width:100%;">
          </figure>

          <p class="grey-box" style="text-align:justify;">
            The ground-truth mask is skeletonised and converted to a graph. 
            In every iteration we sample a connected vertex pair and find its shortest path with Dijkstra’s algorithm; this path has zero cost because the label is perfectly connected. 
            The two vertices are then shifted to the lowest-cost pixels within a small window on the network’s predicted distance map, providing tolerance to minor mis-alignments. 
            Fixing those endpoints, we apply Dijkstra again on the prediction. 
            The L<sub>CAPE</sub> for this pair is the sum of squared distance values along that predicted path—close to zero when connectivity is correct and larger when a gap is present. 
            Averaging such costs over many pairs and adding them to a standard pixel-wise loss (e.g.&nbsp;MSE) yields the total objective used for back-propagation.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: justify;">
          <h2 class="title is-3 has-text-centered">Masking Strategy</h2>
          
          <figure class="has-text-centered">
            <img src="./static/images/FIG_MASK.png" alt="CAPE connectivity result" style="width:100%;">
          </figure>
          <p class="grey-box" style="text-align:justify;">
            We convert the ground-truth path into a binary mask \(M\) and dilate it by 10&nbsp;pixels to obtain \(M_{\text{dilated}}\).
            Multiplying the predicted distance map \(\hat{y}\) by this dilated mask assigns an infinite cost to every pixel outside the mask.
            Dijkstra’s algorithm is then run between the projected vertices \(v'_1\) and \(v'_2\) on the masked map.
            Because the search is confined to the dilated region, it cannot bypass a disconnection through a loop, and the number of pixels examined is smaller, which reduces the computation time of the loss.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>





<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using CAPE, we improve the connectivity of curvilinear structures while preserving details. The figure below shows a successful reconstruction.
          </p>
          <img src="./static/images/FIG_NEW.png" alt="CAPE visual effect example" style="width:100%;">
        </div>
      </div>
      <div class="column">
        <h2 class="title is-3">Connectivity Enforcement</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              CAPE effectively preserves the connectivity of neuronal and vascular structures. The illustration below highlights improved segmentation compared to alternative methods.
            </p>
            <img src="./static/images/FIG_MASK.png" alt="CAPE connectivity result" style="width:100%;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Vertex&nbsp;Shifting</h2>

    <!-- Video demo -->
    <figure class="has-text-centered">
      <video autoplay muted loop playsinline style="width:50%; height:auto;">
        <source src="./static/videos/shifting.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </figure>


    <!-- Explanation -->
    <p class="grey-box" style="text-align:justify;">
      Directly mapping a graph vertex to the corresponding pixel in the predicted distance map \(\hat{y}\) can penalise the model for errors introduced by noisy center-line annotations.  
      To mitigate this, each vertex \(v\) is relocated to the pixel within a radius of \(r = 5\) px that minimises \(\hat{y}(v)\).  
      Formally, the shifted position is  
      \[
        v' \;=\; \arg\min_{u \in \mathcal{N}_r(v)} \hat{y}(u),
      \]
      where \(\mathcal{N}_r(v)\) denotes the square (or cubic) neighbourhood of side length \(2r+1\) centerd at \(v\).  
      This operation keeps the endpoints aligned with the predicted center line, providing a more stable starting point for the masked shortest-path search and yielding smoother gradients during optimisation.
    </p>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Algorithm</h2>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <figure class="has-text-centered">
          <img src="./static/images/code.png" alt="Algorithm code snapshot" style="width:95%; max-width:800px;">
        </figure>
        <p class="grey-box" style="text-align:justify;">
          <strong>Overall&nbsp;algorithm.</strong>
          We iteratively samples vertex pairs until every edge of the ground-truth graph has been processed. For each pair the shortest path is extracted, the corresponding mask is generated and then it is dilated. The vertices are shifted on the prediction to compensate for the noisy center-line annotations. Then, shortest path within the masked region is computed.  The squared distance values accumulated along all predicted paths define L<sub>CAPE</sub>. 
        </p>
      </div>
    </div>
  </div>
</section>



<section class="section" id="cape-reference">
  <div class="container is-max-desktop">
    <div class="box">
      <!-- Title and Signature -->
      <header class="card-header has-background-info-light">
        <p class="card-header-title has-text-info-dark is-size-3 has-text-weight-bold">
          Usage&nbsp;<span style="color: rgba(115, 126, 131, 0.555);"> / CAPE</span>
        </p>
      </header>
      <br>

      <!-- Short Description -->
      <p style="text-align:justify;">
        The 
        <a href="https://github.com/NeuraVisionLab/CAPE/blob/main/loss.py" class="has-text-info has-text-weight-semibold">
          CAPE loss module
        </a> 
        compares shortest paths in predicted and ground-truth distance maps. It samples random node pairs
        from the ground-truth graph (or skeletonized mask) and penalizes deviations in path cost via Dijkstra’s algorithm.
      </p>

      <br>

      <pre class="code-border"><code class="language-python">class CAPE(nn.Module):
    def __init__(
        self, window_size=128, three_dimensional=False, dilation_radius=10, shifting_radius=5, is_binary=False, 
        distance_threshold=20, single_edge=False
    )</code></pre>

      

      <!-- Parameters -->
      <h2 class="title is-6 has-background-light" style="margin-bottom: -0.5rem; margin-top: 1rem; padding-left: 0.2rem; padding-top: 0.2rem; padding-bottom: 0.2rem;">Parameters</h2>
      <dl style="margin-top: 1rem;">
        <dt><strong>window_size&nbsp; : &nbsp;<em>int</em> (default=128)</strong></dt>
        <dd style="margin-left: 1rem; margin-bottom: 0.5rem;">
          Size of each square patch (2D) or cubic volume (3D) to process at a time.
        </dd>

        <dt><strong>three_dimensional&nbsp; : &nbsp;<em>bool</em> (default=False)</strong></dt>
        <dd style="margin-left: 1rem; margin-bottom: 0.5rem;">
          If True, operate on 3D volumes (D×H×W); otherwise, on 2D images (H×W).
        </dd>

        <dt><strong>dilation_radius&nbsp; : &nbsp;<em>int</em> (default=10)</strong></dt>
        <dd style="margin-left: 1rem; margin-bottom: 0.5rem;">
          Radius (in pixels/voxels) to dilate ground-truth paths for masking.
        </dd>

        <dt><strong>shifting_radius&nbsp; : &nbsp;<em>int</em> (default=5)</strong></dt>
        <dd style="margin-left: 1rem; margin-bottom: 0.5rem;">
          Radius (in pixels/voxels) to refine start/end points to lowest-cost nearby pixels.
        </dd>

        <dt><strong>is_binary&nbsp; : &nbsp;<em>bool</em> (default=False)</strong></dt>
        <dd style="margin-left: 1rem; margin-bottom: 0.5rem;">
          If True, operate on binary maps rather than distance maps.
        </dd>

        <dt><strong>distance_threshold&nbsp; : &nbsp;<em>float</em> (default=20)</strong></dt>
        <dd style="margin-left: 1rem; margin-bottom: 0.5rem;">
          Maximum value used for clipping ground-truth distance maps.
        </dd>

        <dt><strong>single_edge&nbsp; : &nbsp;<em>bool</em> (default=False)</strong></dt>
        <dd style="margin-left: 1rem; margin-bottom: 0.5rem;">
          If True, sample a single edge at a time; otherwise, sample a path.
        </dd>
      </dl>

      <!-- Returns -->
      <h2 class="title is-6 has-background-light mt-5" style="margin-bottom: -0.5rem; margin-top: 1rem; padding-left: 0.2rem; padding-top: 0.2rem; padding-bottom: 0.2rem;">Returns</h2>
      <dl style="margin-top: 1rem;">
        <dt><strong>loss&nbsp; : &nbsp;<em>torch.Tensor</em></strong></dt>
        <dd style="margin-left: 1rem;">
          A scalar tensor representing the average CAPE loss over the batch.
        </dd>
      </dl>

      <!-- Notes -->
      <h2 class="title is-6 has-background-light mt-5" style="margin-bottom: -0.5rem; margin-top: 1rem; padding-left: 0.2rem; padding-top: 0.2rem; padding-bottom: 0.2rem;">Notes</h2>
      <div class="notification is-info is-light" style="margin-top: 1rem;">
        <ul>
          <li>Predictions must be a <code>torch.Tensor</code> of shape <code>(batch, H, W)</code> for 2D or <code>(batch, D, H, W)</code> for 3D.</li>
          <li>Ground truths can be a list of graphs in <code>networkx.Graph</code> format, or images (<code>np.ndarray</code> or <code>torch.Tensor</code>) of the same shape as prediction.
          <!-- <li>Constructs the skeleton graph with <code>graph_from_skeleton_2D</code> or <code>graph_from_skeleton_3D</code>.</li> -->
        </ul>
      </div>
    </div>
  </div>
</section>





<!-- ───────────────────── Graph Extraction & Export ───────────────────── -->
<section class="section" id="graph-export">
  <div class="container is-max-desktop">

    <!-- <h2 class="title is-3 has-text-centered">Graph&nbsp;Extraction</h2> -->

    


    <div class="box">
      <!-- Title and Signature -->
      <header class="card-header has-background-info-light">
        <p class="card-header-title has-text-info-dark is-size-3 has-text-weight-bold">
          Usage&nbsp;<span style="color: rgba(115, 126, 131, 0.555);"> / Graph extraction</span>
        </p>
      </header>
      <br>

      <!-- overview -->
    <p style="text-align:justify;">
      The <code>utils</code> folder contains our implementation of two key functions—<code>graph_from_skeleton_2D</code> and
      <code>graph_from_skeleton_3D</code> which CAPE uses. Each one turns an skeleton mask into an undirected
      <code>networkx.Graph</code>. We also include helper functions for cropping these graphs into smaller
      patches under the same directory. 
    <br><br>
      For large datasets it is faster to build graphs once and cache them rather than regenerate 
      them at every training step. Our helper <code>extract_graph.py</code> wraps 
       the <code>graph_from_skeleton_2D</code> and <code>graph_from_skeleton_3D</code> functions: 
       each binary <code>.npy</code> mask is converted to a <code>networkx.Graph</code> 
       and the result is saved as <code>.gpickle</code>. 
    </p>

    <!-- quick CLI -->
    <p style="margin-top:1rem;"><strong>Saving examples:</strong></p>

    <pre class="code-border"><code class="language-bash"># 2-D masks → graphs (saved to data_as_graphs)
python extract_graph.py npy_images

# 3-D volumes → graphs (custom output directory)
python extract_graph.py brain_vols --dim 3 --out_dir brain_graphs
    </code></pre>



    <!-- key options -->
    <div class="content" style="margin-top:1.2rem;">
      <dl>
        <p style="margin-top:1rem;"><strong>Options:</strong></p>
        <dt><code>--dim&nbsp;{2&nbsp;|&nbsp;3}</code></dt>
        <dd>Choose the 2-D or 3-D skeleton-to-graph routine&nbsp;·&nbsp;<em>default&nbsp;2</em></dd>
        
        <dt><code>--threshold&nbsp;&lt;T&gt;</code></dt>
        <dd>Binarise masks whose values are not already 0/1&nbsp;·&nbsp;<em>default&nbsp;0.5</em></dd>

        <dt><code>--out_dir&nbsp;&lt;DIR&gt;</code></dt>
        <dd>Destination folder for the generated <code>.gpickle</code> files&nbsp;·&nbsp;<em>default&nbsp;data_as_graph</em></dd>
      </dl>
    </div>

    <!-- load example -->
    <p style="margin-top:1rem;"><strong>Loading example:</strong></p>
<pre class="code-border"><code class="language-python">from extract_graph import read_gpickle

gpickle_path = "data_as_graph/example_graph.gpickle"
G = read_gpickle(gpickle_path)
</code></pre>
  </div>

  </div>
</section>
<!-- ────────────────────────────────────────────────────────────────────── -->



<section class="section" id="results">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Results</h2>
    
    <div class="table-container">
      <table class="table is-fullwidth has-text-centered no-borders center-table-cells">
        <thead>
          <tr>
            <th></th>
            <th>Input</th>
            <th>Label</th>
            <th>Perc</th>
            <th>clDice</th>
            <th>MALIS</th>
            <th>CAPE</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <th>CREMI</th>
            <td><img src="./static/images/cremi_image.png" alt="CREMI Input" ></td>
            <td><img src="./static/images/cremi_label.png" alt="CREMI Label" ></td>
            <td><img src="./static/images/cremi_agata.png" alt="CREMI Perc" ></td>
            <td><img src="./static/images/cremi_clDice.png" alt="CREMI clDice" ></td>
            <td><img src="./static/images/cremi_malis.png" alt="CREMI InvMALIS" ></td>
            <td><img src="./static/images/cremi_ours.png" alt="CREMI CAPE" ></td>
          </tr>
          <tr>
            <th>DRIVE</th>
            <td><img src="./static/images/drive_image.png" alt="DRIVE Input" ></td>
            <td><img src="./static/images/drive_label.png" alt="DRIVE Label" ></td>
            <td><img src="./static/images/drive_agata.png" alt="DRIVE Perc" ></td>
            <td><img src="./static/images/drive_clDice.png" alt="DRIVE clDice" ></td>
            <td><img src="./static/images/drive_malis.png" alt="DRIVE InvMALIS" ></td>
            <td><img src="./static/images/drive_ours.png" alt="DRIVE CAPE" ></td>
          </tr>
          <tr>
            <th>Brain</th>
            <td><img src="./static/images/brain_image.png" alt="Brain Input" ></td>
            <td><img src="./static/images/brain_label.png" alt="Brain Label" ></td>
            <td><img src="./static/images/brain_agata.png" alt="Brain Perc" ></td>
            <td><img src="./static/images/brain_clDice.png" alt="Brain clDice" ></td>
            <td><img src="./static/images/brain_malis.png" alt="Brain InvMALIS" ></td>
            <td><img src="./static/images/brain_ours.png" alt="Brain CAPE" ></td>
          </tr>
        </tbody>
      </table>
    </div>
    <div class="content has-text-centered has-text-justified grey-box">
      <p>
        Qualitative comparison of the test results in 2D and 3D datasets. The arrows highlight regions that remain disconnected in alternative methods but are successfully connected using CAPE. The connectivity improves significantly when our approach is used.
      </p>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>

    <div style="position: relative;">
      <button 
        id="copyBibTeXBtn" 
        style="
          position: absolute; 
          right: 10px; 
          top: 10px; 
          background-color: #3273dc; 
          color: white; 
          border: none; 
          padding: 0.4em 0.8em; 
          border-radius: 4px; 
          cursor: pointer;
          font-size: 0.9em;
        ">
        Copy
      </button>
      <pre id="bibtexCode" style="overflow-x:auto; padding-top: 2.5em;"><code>@misc{esmaeilzadeh2025CAPE,
        title={CAPE: Connectivity-Aware Path Enforcement Loss for Curvilinear Structure Delineation}, 
        author={Elyar Esmaeilzadeh and Ehsan Garaaghaji and Farzad Hallaji Azad and Doruk Oner},
        year={2025},
        eprint={2504.00753},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2504.00753}, 
  }
</code></pre>
    </div>
  </div>
</section>

<script>
  document.getElementById('copyBibTeXBtn').addEventListener('click', () => {
    const text = document.getElementById('bibtexCode').innerText;
    navigator.clipboard.writeText(text).then(() => {
      // Optional: change button text briefly to show success
      const btn = document.getElementById('copyBibTeXBtn');
      btn.innerText = 'Copied!';
      setTimeout(() => btn.innerText = 'Copy', 2000);
    });
  });
</script>

<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>
